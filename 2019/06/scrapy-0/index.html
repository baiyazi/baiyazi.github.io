<!DOCTYPE HTML>
<html lang="zh-Hans">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="scrapy-0 |  Python爬虫基础 一, 梦否,学习之路,大前端开发">
    <meta name="description" content="
感觉学习Scrapy之前，应该是爬虫的基础类库。毕竟Scrapy是框架，学习框架之前应该弄熟练基础的类库的使用。

1. 数据来源：
大型互联网公司
百度指数
阿里指数
新浪指数


政府机构
中华人民共和国国家统计局 （http://d">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>scrapy-0 |  Python爬虫基础 一 | 梦否</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">梦否</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>主页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/lifes" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>生活</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="Search"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">梦否</div>
        <div class="logo-desc">
            
            吞噬你的很多时候不是金涛骇浪，相反是那些普通的日子。
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                主页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类页
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/lifes" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                生活
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/baiyazi" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/baiyazi" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>





<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/16.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        scrapy-0 |  Python爬虫基础 一
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/爬虫初识/" target="_blank">
                                <span class="chip bg-color">爬虫初识</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/scrapy/" class="post-category" target="_blank">
                                scrapy
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2019-06-04
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>Word Count:&nbsp;&nbsp;
                        10.6k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>Read Times:&nbsp;&nbsp;
                        48 Min
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>感觉学习<code>Scrapy</code>之前，应该是爬虫的基础类库。毕竟<code>Scrapy</code>是框架，学习框架之前应该弄熟练基础的类库的使用。</p>
</blockquote>
<h1 id="1-数据来源："><a href="#1-数据来源：" class="headerlink" title="1. 数据来源："></a>1. 数据来源：</h1><ol>
<li>大型互联网公司<ul>
<li>百度指数</li>
<li>阿里指数</li>
<li>新浪指数</li>
</ul>
</li>
<li>政府机构<ul>
<li>中华人民共和国国家统计局 （<a href="http://data.stats.gov.cn/" target="_blank" rel="noopener">http://data.stats.gov.cn/</a> ）</li>
<li>世界银行公开数据 （<a href="https://data.worldbank.org.cn/" target="_blank" rel="noopener">https://data.worldbank.org.cn/</a> ）</li>
<li>纳斯达克股票信息 （<a href="https://www.nasdaq.com/zh" target="_blank" rel="noopener">https://www.nasdaq.com/zh</a> ）</li>
<li>联合国统计的数据 （<a href="https://data.un.org" target="_blank" rel="noopener">https://data.un.org</a> ）</li>
</ul>
</li>
<li>咨询公司<ul>
<li>艾瑞咨询</li>
<li>麦肯锡</li>
</ul>
</li>
<li>第三方数据平台<ul>
<li>数据堂 （<a href="http://www.datatang.com" target="_blank" rel="noopener">www.datatang.com</a> ）</li>
<li>贵阳大数据交易所 （trade.gbdex.com ）</li>
</ul>
</li>
<li>爬虫爬取</li>
</ol>
<h1 id="2-爬虫简介"><a href="#2-爬虫简介" class="headerlink" title="2. 爬虫简介"></a>2. 爬虫简介</h1><p>抓取网页数据的程序</p>
<h2 id="做爬虫的语言"><a href="#做爬虫的语言" class="headerlink" title="做爬虫的语言"></a>做爬虫的语言</h2><p><code>PHP</code>、<code>Java</code>、<code>C/C++</code>、<code>Python</code>等</p>
<h2 id="Scrapy框架"><a href="#Scrapy框架" class="headerlink" title="Scrapy框架"></a>Scrapy框架</h2><p>高定制型高性能（异步网络框架<code>twisted</code>）、高并发，速度下载很快；<br>（还有一个爬虫框架：<code>Pyspider</code>  比较简单）</p>
<h2 id="分布式策略-scrapy-reids"><a href="#分布式策略-scrapy-reids" class="headerlink" title="分布式策略 scrapy-reids"></a>分布式策略 scrapy-reids</h2><p>主要做：请求指纹去重、请求分配、数据临时存储</p>
<h2 id="爬虫、反爬虫、反反爬虫-之间的斗争"><a href="#爬虫、反爬虫、反反爬虫-之间的斗争" class="headerlink" title="爬虫、反爬虫、反反爬虫 之间的斗争"></a>爬虫、反爬虫、反反爬虫 之间的斗争</h2><p>重要的网页数据一般都有反爬虫机制。做爬虫最头疼的不是复杂的页面，而是重要的网站都有反爬虫。<br>但是，网站做反爬虫，还需要考虑成本问题，不是所有的网站都能做到完备的反爬虫策略。<br><code>数据价值=机器成本+人力成本</code></p>
<h1 id="3-爬虫分类"><a href="#3-爬虫分类" class="headerlink" title="3. 爬虫分类"></a>3. 爬虫分类</h1><h2 id="通用爬虫"><a href="#通用爬虫" class="headerlink" title="通用爬虫"></a>通用爬虫</h2><p>搜索引擎用的爬虫系统<br>目标：尽可能的把互联网上的所有网页下载下来，放到本地服务器，然后做相关处理，最后提供一个检索数据的接口。<br>爬取流程：<br>a) 首选选取一部分已有的URL，把这些URL放到待爬取队列。<br>b) 从队列里取出这些URL，然后解析DNS得到主机IP，然后去这个IP对应的服务器里下载HTML页面，保存到搜索引擎的本地服务器。<br>之后把这个爬过的URL放入已爬取队列。<br>c) 分析这些网页内容，找出网页里其他的URL连接，继续执行第二步，直到爬取条件结束。</p>
<p>通用爬虫并不是万物皆可爬，它也需要遵守规则：<br><code>Robots</code>协议：协议会指明通用爬虫可以爬取网页的权限。<br><code>Robots.txt</code> 只是一个建议。并不是所有爬虫都遵守，一般只有大型的搜索引擎爬虫才会遵守。<br>    咱们个人写的爬虫，就不管了。</p>
<p>搜索引擎排名：</p>
<ol>
<li><code>PageRank</code>值：根据网站的流量（点击量/浏览量/人气）统计，流量越高，网站也越值钱，排名越靠前。</li>
<li>竞价排名：谁给钱多，谁排名就高。</li>
</ol>
<h2 id="聚焦爬虫"><a href="#聚焦爬虫" class="headerlink" title="聚焦爬虫"></a>聚焦爬虫</h2><p>爬虫程序员写的针对某种内容的爬虫。</p>
<h1 id="4-urllib"><a href="#4-urllib" class="headerlink" title="4. urllib"></a>4. urllib</h1><p>在<code>Python2</code>中，是<code>urllib2</code> ；在 <code>python3.x</code>中被改为<code>urllib.request</code></p>
<p>看看下面简单的例子：</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Python3.6</span>
<span class="token comment" spellcheck="true">#导入库</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token comment" spellcheck="true"># 发送url地址，得到响应对象</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span><span class="token string">"http://127.0.0.1:4000"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># read()方法读取文件全部内容</span>
html <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 打印源码</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>html<span class="token punctuation">)</span></code></pre>
<p>直接使用<code>urlopen</code>打开网页，默认的 <code>User-Agent：&quot;Python-urllib/%s&quot; % __version__</code></p>
<p><code>User-Agent</code>:<span style="color:orange;font-weight:bolder;"> 是爬虫和反爬虫斗争的第一步</span>，养成好习惯，发送请求带<code>User-Agent</code><br>我们就需要自己构造一个和浏览器请求很相似的<code>web请求</code>，也就是使用<code>Request</code>。<br>参数比较多，这里列出部分参数：</p>
<ul>
<li>请求的<code>url</code>地址</li>
<li>请求头<code>headers</code>，类型是一个字典{}</li>
<li>请求的方法 <code>method</code>，默认值是<code>None</code></li>
</ul>
<p>略微了解HTTP协议的就知道，在请求头中就可以设置请求的各种参数，其中就有我们期望的<code>User-Agent</code>。</p>
<h2 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h2><p>下面就简单构造一个<code>Request</code>：</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Python3</span>
<span class="token comment" spellcheck="true">#导入库</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token comment" spellcheck="true"># 构造Request</span>
request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url<span class="token operator">=</span><span class="token string">"http://127.0.0.1:4000"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 发送url地址，得到响应对象</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># read()方法读取文件全部内容</span>
html <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>html<span class="token punctuation">)</span></code></pre>
<p>运行后，发现结果和上一个例子的效果一模一样。<br>上面也提到了，可以传入请求头，所以我么下面就来实践一下：<br>打开浏览器，还是以我们前面的网址为例，然后抓包看看它的请求头信息（部分）：</p>
<blockquote>
<p>Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,<em>/</em>;q=0.8<br>Accept-Encoding: gzip, deflate, br<br>Accept-Language: zh-CN,zh;q=0.9<br>Cache-Control: max-age=0<br>Connection: keep-alive<br>Cookie: Hm_lvt_3e7b72d8c528abb722783061a44884f5=1560069575; Hm_lpvt_3e7b72d8c528abb722783061a44884f5=1560512154; scroll-cookie=267|/<br>Host: 127.0.0.1:4000<br>Upgrade-Insecure-Requests: 1<br>User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36</p>
</blockquote>
<p>却不一定都需要，如<code>Accept-Encoding</code>就不需要，我们做爬虫不需要费劲的将数据下载后，然后还要解压，直接得到数据不是更好。有些可要可不要，如：<code>Host</code>、<code>Accept-Language</code>、<code>Cache-Control</code>、<code>Connection</code>、<code>Upgrade-Insecure-Requests</code>。<br>而<code>Cookie</code>主要是处理登录的时候的，如果只是爬取静态页面也是不需要的。</p>
<h2 id="User-Agent"><a href="#User-Agent" class="headerlink" title="User-Agent"></a>User-Agent</h2><p>爬取静态页面，只要<code>User-Agent</code>就可以了。</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Python3</span>
<span class="token comment" spellcheck="true">#导入库</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token comment" spellcheck="true"># 构造Request</span>
request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url<span class="token operator">=</span><span class="token string">"http://127.0.0.1:4000"</span><span class="token punctuation">,</span> headers<span class="token operator">=</span><span class="token punctuation">{</span>
<span class="token string">"User-Agent"</span><span class="token punctuation">:</span><span class="token string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36"</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 发送url地址，得到响应对象</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># read()方法读取文件全部内容</span>
html <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>html<span class="token punctuation">)</span></code></pre>
<p>运行结果还是和上面的例子效果一样，可能会有一种无卵用的觉悟。<br>但是，<span style="color:orange;font-weight:bolder;">如果不修改默认的<code>User-Agent</code>，你爬虫的IP是很容易被所爬取的目标网站封掉的</span>。</p>
<h2 id="Response"><a href="#Response" class="headerlink" title="Response"></a>Response</h2><p>是服务器响应的类文件，除了支持文件操作的方法外，还支持一些和服务器响应先关的方法。<br>我们可以在上面的程序中加入：<code>print(dir(response))</code>以查看<code>response</code>所具有的方法。结果如下：</p>
<blockquote>
<p>[‘<strong>abstractmethods</strong>‘, ‘<strong>class</strong>‘, ‘<strong>del</strong>‘, ‘<strong>delattr</strong>‘, ‘<strong>dict</strong>‘, ‘<strong>dir</strong>‘, ‘<strong>doc</strong>‘, ‘<strong>enter</strong>‘, ‘<strong>eq</strong>‘, ‘<strong>exit</strong>‘, ‘<strong>format</strong>‘, ‘<strong>ge</strong>‘, ‘<strong>getattribute</strong>‘, ‘<strong>gt</strong>‘, ‘<strong>hash</strong>‘, ‘<strong>init</strong>‘, ‘<strong>init_subclass</strong>‘, ‘<strong>iter</strong>‘, ‘<strong>le</strong>‘, ‘<strong>lt</strong>‘, ‘<strong>module</strong>‘, ‘<strong>ne</strong>‘, ‘<strong>new</strong>‘, ‘<strong>next</strong>‘, ‘<strong>reduce</strong>‘, ‘<strong>reduce_ex</strong>‘, ‘<strong>repr</strong>‘, ‘<strong>setattr</strong>‘, ‘<strong>sizeof</strong>‘, ‘<strong>str</strong>‘, ‘<strong>subclasshook</strong>‘, ‘_abc_cache’, ‘_abc_negative_cache’, ‘_abc_negative_cache_version’, ‘_abc_registry’, ‘_checkClosed’, ‘_checkReadable’, ‘_checkSeekable’, ‘_checkWritable’, ‘_check_close’, ‘_close_conn’, ‘_get_chunk_left’, ‘_method’, ‘_peek_chunked’, ‘_read1_chunked’, ‘_read_and_discard_trailer’, ‘_read_next_chunk_size’, ‘_read_status’, ‘_readall_chunked’, ‘_readinto_chunked’, ‘_safe_read’, ‘_safe_readinto’, ‘begin’, ‘chunk_left’, ‘chunked’, ‘close’, ‘closed’, ‘code’, ‘debuglevel’, ‘detach’, ‘fileno’, ‘flush’, ‘fp’, ‘getcode’, ‘getheader’, ‘getheaders’, ‘geturl’, ‘headers’, ‘info’, ‘isatty’, ‘isclosed’, ‘length’, ‘msg’, ‘peek’, ‘read’, ‘read1’, ‘readable’, ‘readinto’, ‘readinto1’, ‘readline’, ‘readlines’, ‘reason’, ‘seek’, ‘seekable’, ‘status’, ‘tell’, ‘truncate’, ‘url’, ‘version’, ‘will_close’, ‘writable’, ‘write’, ‘writelines’]</p>
</blockquote>
<p>首先，加粗的是私有方法，我们选择<code>readline</code>来测试一下：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>readline<span class="token punctuation">)</span></code></pre>
<p><span class="title2">结果：</span><br><code>&lt;bound method HTTPResponse.readline of &lt;http.client.HTTPResponse object at 0x0000000002A31828&gt;&gt;</code></p>
<p>所以我们这里可以在<code>Pycharm</code>中导入<code>Response</code>相关的包，然后追踪一下代码：<br>在<code>Pycharm</code>中导包：<code>from http.client import HTTPResponse</code><br>然后按住<code>Ctrl+单击HTTPResponse</code>，结果如下（选取部分方法）：</p>
<h3 id="文件特性"><a href="#文件特性" class="headerlink" title="文件特性"></a>文件特性</h3><ul>
<li><strong>close</strong></li>
<li><strong>flush</strong></li>
<li><strong>isclosed</strong></li>
<li><strong>read</strong>   &nbsp;&nbsp;&nbsp;&nbsp;读完后，直接关闭流，可以用上一个方法测试</li>
<li><strong>readline</strong>  &nbsp;&nbsp;&nbsp;&nbsp;每次读一行，文件没有读完就不会关闭流对象，也可以测试，同上。</li>
</ul>
<h3 id="响应相关"><a href="#响应相关" class="headerlink" title="响应相关"></a>响应相关</h3><ul>
<li><strong>getheaders</strong>  &nbsp;&nbsp;&nbsp;&nbsp;获取响应头的信息，如：<code>print(response.getheaders())</code>。<br>结果是：<code>[(&#39;X-Powered-By&#39;, &#39;Hexo&#39;), (&#39;Content-Type&#39;, &#39;text/html&#39;), (&#39;Date&#39;, &#39;Sat, 15 Jun 2019 06:43:17 GMT&#39;), (&#39;Connection&#39;, &#39;close&#39;), (&#39;Transfer-Encoding&#39;, &#39;chunked&#39;)]</code></li>
<li><strong>info</strong>  &nbsp;&nbsp;&nbsp;&nbsp;和上一个想过一样，获取响应头的信息，如：<code>print(response.info())</code>。不同的是，得到的是一个<code>http.client.HTTPMessage</code>消息对象</li>
<li><strong>getheader</strong>（name） &nbsp;&nbsp;&nbsp;&nbsp;不难理解，获取单个响应头的信息</li>
<li><strong>geturl</strong>   &nbsp;&nbsp;&nbsp;&nbsp;得到当前响应页面的<code>URL</code>，看<code>URL</code>就可以知道是哪个页面返回的数据，就可以防止重定向问题。</li>
<li><strong>getcode</strong>  &nbsp;&nbsp;&nbsp;&nbsp;得到和<code>response</code>响应一块发送的<code>HTTP状态码</code>，下面我们看看响应码：<br>成功200，3是重定向，4服务器页面出错，5服务器本身问题</li>
</ul>
<h2 id="Get方式数据编码传输"><a href="#Get方式数据编码传输" class="headerlink" title="Get方式数据编码传输"></a>Get方式数据编码传输</h2><h3 id="1-URL编码"><a href="#1-URL编码" class="headerlink" title="1. URL编码"></a>1. URL编码</h3><p>在请求链接中的汉字，通常都需要进行<code>URL编码</code>。在<code>urllib</code>中使用<code>urlencode</code>函数来解决汉字编码问题。<br><strong>python2.x</strong>：<code>urllib.urlencode({&#39;wd&#39;:&quot;测试&quot;})</code><br><strong>python3.x</strong>：<code>from urllib.parse import urlencode</code>  按照惯例，这里还是追踪一下，可以看见原型中的注解：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">urlencode</span><span class="token punctuation">(</span>query<span class="token punctuation">,</span> doseq<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> safe<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span>None<span class="token punctuation">,</span> errors<span class="token operator">=</span>None<span class="token punctuation">,</span> quote_via<span class="token operator">=</span>quote_plus<span class="token punctuation">)</span><span class="token punctuation">:</span></code></pre>
<blockquote>
<p>Encode a dict or sequence of two-element tuples into a URL query string.<br>编码一个字典或者一个两个元素的元组序列到一个URL参数串</p>
</blockquote>
<p>以百度搜索为例：<br>百度关键字搜索的<code>GET</code>形式的<code>URL</code>地址为：<code>https://www.baidu.com/s?wd=urllib.urlencode</code><br>后面还有一大堆参数，但是实际上是没有什么用处的，上面的链接就可以搜索关于<code>urllib.urlencode</code>的相关消息。所以下面也利用一下：<br>先看看编码的代码：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> urlencode
name <span class="token operator">=</span> urlencode<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'wd'</span><span class="token punctuation">:</span><span class="token string">"无涯明月"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#wd=%E6%97%A0%E6%B6%AF%E6%98%8E%E6%9C%88</span></code></pre>
<h3 id="2-解码"><a href="#2-解码" class="headerlink" title="2. 解码"></a>2. 解码</h3><p>当然，还有解码，也还是需要提前了解的，使用<code>unquote</code><br><strong>python2.x中</strong>：<code>urllib.unquote(name)</code><br><strong>python3.x中</strong>：<code>from urllib.parse import unquote</code>  这里还是追踪一下：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">unquote</span><span class="token punctuation">(</span>string<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">,</span> errors<span class="token operator">=</span><span class="token string">'replace'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></code></pre>
<p>默认使用<code>utf-8</code>解码。不妨看看上面编码后的解码：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> urlencode
name <span class="token operator">=</span> urlencode<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'wd'</span><span class="token punctuation">:</span><span class="token string">"无涯明月"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#wd=%E6%97%A0%E6%B6%AF%E6%98%8E%E6%9C%88</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> unquote
name <span class="token operator">=</span> unquote<span class="token punctuation">(</span>name<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#wd=无涯明月</span></code></pre>
<p>这里就给出百度搜索的简单案例：</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Python3</span>
<span class="token comment" spellcheck="true">#导入库</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> urlencode
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> unquote


url <span class="token operator">=</span> <span class="token string">"http://www.baidu.com/s?"</span>
keyword <span class="token operator">=</span> input<span class="token punctuation">(</span><span class="token string">"请输入您要查询的关键字："</span><span class="token punctuation">)</span>
wd <span class="token operator">=</span> urlencode<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'wd'</span><span class="token punctuation">:</span>keyword<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>wd<span class="token punctuation">)</span>
from_url <span class="token operator">=</span> url <span class="token operator">+</span> wd
<span class="token comment" spellcheck="true"># 构造Request</span>
request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url<span class="token operator">=</span>from_url<span class="token punctuation">,</span> headers<span class="token operator">=</span><span class="token punctuation">{</span>
<span class="token string">"User-Agent"</span><span class="token punctuation">:</span><span class="token string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36"</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># 发送url地址，得到响应对象</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>

page <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>page<span class="token punctuation">)</span></code></pre>
<p>当然，结果比较尴尬，就是<code>page</code>是字节类型（不妨用<code>type(page)</code>检测），不方便我们查看，下面给出转换成字符串的方法：</p>
<pre class=" language-python"><code class="language-python">page <span class="token operator">=</span> page<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>page<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#可以搜索一下结果，发现是正确的</span></code></pre>
<p>以百度贴吧为例，我们这里打开百度贴吧，搜索高考，然后点击第二页：<br><img src="/images/201906/2019-06-16_123122.jpg" alt="e"><br>上面的链接我这里放置在这里：<code>http://tieba.baidu.com/f?kw=%E9%AB%98%E8%80%83&amp;ie=utf-8&amp;pn=50</code><br>然后，我们点击第三页：<br><img src="/images/201906/2019-06-16_123457.jpg" alt="e"><br>上面的链接我这里放置在这里：<code>http://tieba.baidu.com/f?kw=%E9%AB%98%E8%80%83&amp;ie=utf-8&amp;pn=100</code></p>
<p>所以，页面链接的变化就是pn的变化：<code>0 - pn=0</code> &nbsp;&nbsp;<code>1 - pn=50</code>&nbsp;&nbsp;…<br>案例代码如下：</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># coding:utf-8</span>
<span class="token comment" spellcheck="true"># Python3</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> urlencode
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> unquote

<span class="token keyword">def</span> <span class="token function">loadPage</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    根据URL发送请求，获取服务器响应文件
    :param url: 需要爬取的URL地址
    :return: 爬取的响应内容
    """</span>
    request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span><span class="token punctuation">{</span>
        <span class="token string">"User-Agent"</span><span class="token punctuation">:</span><span class="token string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36"</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>

    page <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正在下载..."</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> page

<span class="token keyword">def</span> <span class="token function">writePage</span><span class="token punctuation">(</span>page<span class="token punctuation">,</span> file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    保存爬取的数据到到本地文件中
    :param page: 页面数据
    :param file_name: 保存的文件的名称
    :return: 无
    """</span>
    <span class="token comment" spellcheck="true"># 由于page是bytes，这里需要转换一下</span>
    page <span class="token operator">=</span> page<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>page<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">spider</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> startPage<span class="token punctuation">,</span> endPage<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    更具url地址，和每一个的特点，计算打开页面的最终的链接
    :param url: baseUrl
    :param startPage: 起始页
    :param endPage: 结束页
    :return: 无
    """</span>
    start <span class="token operator">=</span> int<span class="token punctuation">(</span>startPage<span class="token punctuation">)</span>
    end <span class="token operator">=</span> int<span class="token punctuation">(</span>endPage<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        pn <span class="token operator">=</span> <span class="token punctuation">(</span>i<span class="token number">-1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">50</span>
        full_url <span class="token operator">=</span> url <span class="token operator">+</span><span class="token string">"&amp;pn="</span><span class="token operator">+</span> str<span class="token punctuation">(</span>pn<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"开始下载"</span><span class="token punctuation">.</span>center<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token string">"-"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        file_name <span class="token operator">=</span> <span class="token string">"第"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span><span class="token string">"页.html"</span>
        page <span class="token operator">=</span> loadPage<span class="token punctuation">(</span>full_url<span class="token punctuation">)</span>
        writePage<span class="token punctuation">(</span>page<span class="token punctuation">,</span> file_name<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"完成下载"</span><span class="token punctuation">.</span>center<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token string">"-"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    kw <span class="token operator">=</span> input<span class="token punctuation">(</span><span class="token string">"请输入你要爬取的贴吧："</span><span class="token punctuation">)</span>
    startPage <span class="token operator">=</span> input<span class="token punctuation">(</span><span class="token string">"请输入起始页："</span><span class="token punctuation">)</span>
    endPage <span class="token operator">=</span> input<span class="token punctuation">(</span><span class="token string">"请输入结束页："</span><span class="token punctuation">)</span>
    url <span class="token operator">=</span> <span class="token string">"http://tieba.baidu.com/f?"</span>
    kw <span class="token operator">=</span> urlencode<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'kw'</span><span class="token punctuation">:</span>kw<span class="token punctuation">}</span><span class="token punctuation">)</span>
    url <span class="token operator">+=</span> kw
    spider<span class="token punctuation">(</span>url<span class="token punctuation">,</span> startPage<span class="token punctuation">,</span> endPage<span class="token punctuation">)</span></code></pre>
<p>上面也就是使用<code>GET</code>方式来获取数据的案例，下面看看<code>Post</code>方式的案例。</p>
<h2 id="Post方式数据编码传输"><a href="#Post方式数据编码传输" class="headerlink" title="Post方式数据编码传输"></a>Post方式数据编码传输</h2><p>以有道翻译为例，打开网址：<code>http://fanyi.youdao.com/</code> ，然后我们使用浏览器检查工具对数据包进行抓包，在抓包的时候，为了方便区分资源，可以点击<br>某个数据包后，用<code>Preview</code>对资源进行查看。其中目标的资源包的<code>Preview</code>的内容如下（以输入<code>无</code>翻译为例）：</p>
<pre><code>translateResult: [[{tgt: &quot;There is no&quot;, src: &quot;无&quot;}]]
0: [{tgt: &quot;There is no&quot;, src: &quot;无&quot;}]
0: {tgt: &quot;There is no&quot;, src: &quot;无&quot;}
src: &quot;无&quot;
tgt: &quot;There is no&quot;
type: &quot;zh-CHS2en&quot;</code></pre><p>可以看见翻译的结果是<code>&quot;There is no&quot;</code>，说明数据包找对了。接着开始找他的报文，可以看见<code>Form Data</code>部分，内容如下：</p>
<blockquote>
<p><code>Form Data</code>没有解析前数据<br>i=%E6%97%A0&amp;from=AUTO&amp;to=AUTO&amp;smartresult=dict&amp;client=fanyideskweb&amp;salt<br>=15606713929093&amp;sign=0d66e2cc39af99bb091353d8b05baade&amp;ts=156067139290<br>9&amp;bv=fb2ba7d69650ad4d6ceb3dc46e03624a&amp;doctype=json&amp;version=2.1&amp;keyfrom=f<br>anyi.web&amp;action=FY_BY_CLICKBUTTION</p>
</blockquote>
<p>为了直观，这里点击<code>Form Data</code> 右边的<code>view parsed</code> </p>
<blockquote>
<p>解析有的友好格式：（上面的数据也可以看做是下面的字典数据经过URL编码后的数据格式）<br>i: 无<br>from: AUTO<br>to: AUTO<br>smartresult: dict<br>client: fanyideskweb<br>salt: 15606713929093<br>sign: 0d66e2cc39af99bb091353d8b05baade<br>ts: 1560671392909<br>bv: fb2ba7d69650ad4d6ceb3dc46e03624a<br>doctype: json<br>version: 2.1<br>keyfrom: fanyi.web<br>action: FY_BY_CLICKBUTTION</p>
</blockquote>
<p>同理，可以看见请求的URL地址是：</p>
<pre><code>Request URL: http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule</code></pre><p>很不幸的是，这里用爬虫模拟了一下，然后出现了错误<code>{&quot;errorcode&quot;:50}</code><br>百度了一下，可以去掉链接中的<code>_o</code>解决。试了一下，可以用。</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># coding:utf-8</span>
<span class="token comment" spellcheck="true"># Python3</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> urlencode
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> unquote


url <span class="token operator">=</span> <span class="token string">"http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule"</span>
key <span class="token operator">=</span> input<span class="token punctuation">(</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"i"</span><span class="token punctuation">:</span> key<span class="token punctuation">,</span>
    <span class="token string">"doctype"</span><span class="token punctuation">:</span> <span class="token string">"json"</span>
<span class="token punctuation">}</span>

data <span class="token operator">=</span> urlencode<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token punctuation">)</span>
request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> headers<span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36"</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span> data<span class="token operator">=</span>data<span class="token punctuation">)</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<blockquote>
<p>测试的结果：<br>{“type”:”EN2ZH_CN”,”errorCode”:0,”elapsedTime”:0,”translateResult”:[[{“src”:”My name is Tom”,”tgt”:”我的名字是汤姆”}]]}<br>{“type”:”ZH_CN2EN”,”errorCode”:0,”elapsedTime”:17,”translateResult”:[[{“src”:”你好，今天天气很好。”,”tgt”:”Hello, it’s a fine day today.”}]]}</p>
</blockquote>
<h2 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h2><p>网站服务器为了辨别用户身份和进行<code>Session</code>跟踪，而储存在用户浏览器上的文本文件。<br>在<code>Cookie</code>中保存了用户名和密码(通常经过<code>RAS</code>加密)，故而可以保持登录信息到用户下次与服务器的会话。<br>比较常见的操作就是在网站服务器端会更具根据<code>Cookie</code>判定注册用户是否已经登录网站。<br>下面，先登录人人网站，然后我们抓捕数据包，取得登录有的<code>Cookie</code>文件，简单<code>Cookie</code>模拟登录：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> <span class="token operator">*</span>

headers <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"Host"</span><span class="token punctuation">:</span><span class="token string">"www.renren.com"</span><span class="token punctuation">,</span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span><span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"</span><span class="token punctuation">,</span>

    <span class="token comment" spellcheck="true"># Cookie里记录了用户名，密码(通常经过RAS加密)</span>
    <span class="token string">"Cookie"</span><span class="token punctuation">:</span> <span class="token string">"anonymid=jwego3......"</span>
<span class="token punctuation">}</span>
request <span class="token operator">=</span> Request<span class="token punctuation">(</span><span class="token string">"http://www.renren.com/"</span><span class="token punctuation">,</span> headers <span class="token operator">=</span> headers<span class="token punctuation">)</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>不妨思考一下，如果每次爬虫都需要手动登录浏览器然后拷贝<code>Cookie</code>下来，还是挺可怕的。在<code>Python</code>中提供了专门的工具来模拟登录，管理<code>Cookie</code>。<br>在这之前，需要先了解一下我们的<code>urlopen</code>函数，追踪一下可以发现包装的核心代码如下：</p>
<pre class=" language-python"><code class="language-python">https_handler <span class="token operator">=</span> HTTPSHandler<span class="token punctuation">(</span>context<span class="token operator">=</span>context<span class="token punctuation">)</span>
opener <span class="token operator">=</span> build_opener<span class="token punctuation">(</span>https_handler<span class="token punctuation">)</span>
opener<span class="token punctuation">.</span>open<span class="token punctuation">(</span>url<span class="token punctuation">,</span> data<span class="token punctuation">,</span> timeout<span class="token punctuation">)</span></code></pre>
<p>由于<code>urlopen()</code>方法不支持代理、<code>cookie</code>等，所以我们如果要程序管理<code>Cookie</code>就需要使用自己包装的<code>open()</code>函数。</p>
<h3 id="HTTPHandler"><a href="#HTTPHandler" class="headerlink" title="HTTPHandler"></a>HTTPHandler</h3><p>先看一个简单的<code>opener()</code>模仿案例：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> <span class="token operator">*</span>

http_hander <span class="token operator">=</span> HTTPHandler<span class="token punctuation">(</span><span class="token punctuation">)</span>
opener <span class="token operator">=</span> build_opener<span class="token punctuation">(</span>http_hander<span class="token punctuation">)</span>
response <span class="token operator">=</span> opener<span class="token punctuation">.</span>open<span class="token punctuation">(</span><span class="token string">"http://www.baidu.com"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#当然这里也可以先用Request包装一下</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h3 id="ProxyHandler"><a href="#ProxyHandler" class="headerlink" title="ProxyHandler"></a>ProxyHandler</h3><p>代理，很多网站会检测某一段时间异常访问的IP，满足条件会禁止这个IP的访问。<br>所以我们可以设置一些代理服务器，每隔一段时间换一个代理，就算IP被禁止，依然可以换个IP继续爬取。<br>下面是一些免费的代理站点：<br><a href="https://www.xicidaili.com/" target="_blank" rel="noopener">西刺免费代理IP</a><br><a href="http://www.kuaidaili.com/" target="_blank" rel="noopener">快代理免费代理</a><br><a href="http://www.goubanjia.com/" target="_blank" rel="noopener">全网代理IP</a><br><a href="http://www.89ip.cn/" target="_blank" rel="noopener">89免费代理</a></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> <span class="token operator">*</span>

proxy_handler <span class="token operator">=</span> ProxyHandler<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"http"</span><span class="token punctuation">:</span><span class="token string">"221.229.252.98:9797"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#nullproxy_handler = urllib2.ProxyHandler({}) 不设置代理</span>
opener <span class="token operator">=</span> build_opener<span class="token punctuation">(</span>proxy_handler<span class="token punctuation">)</span>
response <span class="token operator">=</span> opener<span class="token punctuation">.</span>open<span class="token punctuation">(</span><span class="token string">"http://www.baidu.com"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>Done!，下面就开始账户名、密码登录人人案例：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> urllib<span class="token punctuation">.</span>parse
<span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request
<span class="token keyword">from</span> http <span class="token keyword">import</span> cookiejar

<span class="token comment" spellcheck="true"># 通过cookieJar（）类构建一个cookieJar（）对象，用来保存cookie的值</span>

cookie <span class="token operator">=</span> cookiejar<span class="token punctuation">.</span>CookieJar<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 通过HTTPCookieProcessor（）处理器类构建一个处理器对象，用来处理cookie</span>
<span class="token comment" spellcheck="true"># 参数就是构建的CookieJar（）对象</span>
cookie_handler <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>HTTPCookieProcessor<span class="token punctuation">(</span>cookie<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 构建一个自定义的opener</span>
opener <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>build_opener<span class="token punctuation">(</span>cookie_handler<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 通过自定义opener的addheaders的参数，可以添加HTTP报头参数</span>
opener<span class="token punctuation">.</span>addhandlers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"User-Agent"</span><span class="token punctuation">,</span> <span class="token string">"Opera/9.80 (Windows NT 6.1; U; zh-cn) Presto/2.9.168 Version/11.50"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 人人网的登陆接口</span>
url <span class="token operator">=</span> <span class="token string">"http://www.renren.com/PLogin.do"</span>
<span class="token comment" spellcheck="true"># 需要登陆的账户密码</span>
data <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"email"</span><span class="token punctuation">:</span> <span class="token string">"15128459509"</span><span class="token punctuation">,</span> <span class="token string">"password"</span><span class="token punctuation">:</span> <span class="token string">"xxx"</span><span class="token punctuation">}</span>
<span class="token comment" spellcheck="true"># 通过URL encode（）编码转换</span>
data <span class="token operator">=</span> urllib<span class="token punctuation">.</span>parse<span class="token punctuation">.</span>urlencode<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>

request <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> data<span class="token operator">=</span>data<span class="token punctuation">)</span>
response <span class="token operator">=</span> opener<span class="token punctuation">.</span>open<span class="token punctuation">(</span>request<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>当然，这里只是了解，因为在网站中通常都会做<code>JavaScript</code>加密，然后传输数据。<br>很少有网站会像<a href="http://www.renren.com/PLogin.do" target="_blank" rel="noopener">http://www.renren.com/PLogin.do</a> 一样，直接使用<code>Post</code>方式传送数据。这里只是接触一下，模拟登录还要选择别的技术。</p>
<h1 id="5-Requests"><a href="#5-Requests" class="headerlink" title="5. Requests"></a>5. Requests</h1><p><code>Requests</code>继承了<code>urllib3</code>，连接更加友好。如打开百度：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://www.baidu.com"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span></code></pre>
<p>其余的不说了，不妨百度。</p>
<h1 id="6-数据提取"><a href="#6-数据提取" class="headerlink" title="6. 数据提取"></a>6. 数据提取</h1><p>数据提取有多种方式：</p>
<ol>
<li>正则表达式</li>
<li><code>XPath</code></li>
<li><code>JsonPath</code></li>
<li><code>CSS</code>选择器</li>
</ol>
<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2> <table border="1">
  <tr>
    <td>语法</td>
    <td>说明</td>
  </tr>
  <tr>
    <td colspan="2" style="text-align:center;">字符</td>
  </tr>
  <tr>
    <td>一般字符</td>
    <td> 匹配自身。如：a，即匹配a字符</td>
  </tr>
  <tr>
    <td>. </td>
    <td>匹配除了"\n"外的任意字符（注意：只是一个字符）</td>
  </tr>
  <tr>
    <td>\ </td>
    <td>转义字符。如：\.c，即.c；\c，即\c</td>
  </tr>
  <tr>
    <td>[...]</td>
    <td>字符集，如:[abc]或[a-c]，表示abc；如果是[^abc]，表示不是abc的其他字符</td>
  </tr>
  <tr>
    <td colspan="2" style="text-align:center;">预定义字符</td>
  </tr>
  <tr>
    <td>\d </td>
    <td>表示数字，即[0-9]</td>
  </tr>
  <tr>
    <td>\D </td>
    <td>表示非数字，即[^0-9]</td>
  </tr>
  <tr>
    <td>\s </td>
    <td>表示空白字符，如空格、回车、换行等</td>
  </tr>
  <tr>
    <td>\S </td>
    <td>表示非空白字符，即[^\s]</td>
  </tr>
  <tr>
    <td>\w </td>
    <td>表示单词字符，即[A-Za-z0-9_]</td>
  </tr>
  <tr>
    <td>\W </td>
    <td>非单词字符，即[^\w]</td>
  </tr>
  <tr>
    <td colspan="2" style="text-align:center;">数量词</td>
  </tr>
  <tr>
    <td>* </td>
    <td>表示前一个字符0次或者无限次，如abc*</td>
  </tr>
  <tr>
    <td>+ </td>
    <td>表示匹配前一个字符1次或者无限次</td>
  </tr>
  <tr>
    <td>？ </td>
    <td>表示匹配前一个字符0次或者一次</td>
  </tr>
  <tr>
    <td>{m}</td>
    <td> 表示匹配前一个字符m次</td>
  </tr>
  <tr>
    <td>{m,n} </td>
    <td>表示匹配前一个字符m至n次</td>
  </tr>
  <tr>
    <td colspan="2" style="text-align:center;">边界匹配</td>
  </tr>
  <tr>
    <td>^ </td>
    <td>表示匹配字符串开头，在多行模式中匹配每一行开头</td>
  </tr>
  <tr>
    <td>$</td>
    <td> 表示匹配字符串末尾，在多行模式中匹配每一张末尾</td>
  </tr>
  <tr>
    <td>\A </td>
    <td>表示仅匹配字符串开头</td>
  </tr>
  <tr>
    <td>\Z </td>
    <td>表示仅匹配字符串末尾</td>
  </tr>
  <tr>
    <td>\b </td>
    <td>匹配\w和\W之间</td>
  </tr>
  <tr>
    <td>\B </td>
    <td>表示[^\b]</td>
  </tr>
  <tr>
    <td colspan="2" style="text-align:center;">逻辑与分组</td>
  </tr>
  <tr>
    <td>| </td>
    <td>表示匹配左右表达式中任意一个，先尝试匹配左边的表达式，一旦匹配成功就跳过匹配右边的表达式</td>
  </tr>
  <tr>
    <td>(...) </td>
    <td>被括起来的表达式将被分组，从表达式左边开始每遇到一个分组的左括号'('，编号加一。分组表达式作为一个整体，可以后接数量词，</td>
  </tr>
  </table>

<p>正则匹配比较难，一般不怎么用。这里简单介绍介绍一下用法。在<code>Python</code>中，使用正则表达式需要使用<code>re</code>模块。<code>re</code>模块的一般使用步骤如下：</p>
<ul>
<li>使用 <code>compile()</code> 函数将正则表达式的字符串形式编译为一个 <code>Pattern</code> 对象</li>
<li>通过<code>Pattern</code>对象提供的一系列方法对文本进行匹配查找，获得匹配结果，一个 <code>Match</code> 对象。</li>
<li>最后使用 <code>Match</code>对象提供的属性和方法获得信息，根据需要进行其他的操作</li>
</ul>
<h3 id="Pattern-对象的一些常用方法："><a href="#Pattern-对象的一些常用方法：" class="headerlink" title="Pattern 对象的一些常用方法："></a>Pattern 对象的一些常用方法：</h3><ul>
<li><p><code>match</code> 方法：从起始位置开始查找，一次匹配(而不是所有匹配的结果)。可以自定义查找的起始位置。当匹配成功时，返回一个<code>Match</code> 对象，如果没有匹配上，则返回<code>None</code>。</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 案例一：</span>
<span class="token keyword">import</span> re
strs <span class="token operator">=</span> r<span class="token string">'abc123'</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'\d+'</span><span class="token punctuation">)</span>
resu <span class="token operator">=</span> pattern<span class="token punctuation">.</span>match<span class="token punctuation">(</span>strs<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#下标从0开始，区间为[3, 5)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#12</span>
<span class="token comment" spellcheck="true">#---------------------------------------------------------------</span>
<span class="token comment" spellcheck="true">## 案例二：</span>
<span class="token keyword">import</span> re
strs <span class="token operator">=</span> r<span class="token string">'Hello Tom Hello Jame'</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'([a-z]+) ([a-z]+)'</span><span class="token punctuation">,</span> re<span class="token punctuation">.</span>I<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#re.I表示忽略大小写</span>
resu <span class="token operator">=</span> pattern<span class="token punctuation">.</span>match<span class="token punctuation">(</span>strs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#Hello Tom</span></code></pre>
</li>
<li><p><code>search</code> 方法：从任何位置开始查找，一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果。当匹配成功时，返回一个 <code>Match</code> 对象，如果没有匹配上，则返回<code>None</code>。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> re
strs <span class="token operator">=</span> r<span class="token string">'abc123def456'</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'\d+'</span><span class="token punctuation">)</span>
resu <span class="token operator">=</span> pattern<span class="token punctuation">.</span>search<span class="token punctuation">(</span>strs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#123</span>
resu <span class="token operator">=</span> pattern<span class="token punctuation">.</span>match<span class="token punctuation">(</span>strs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#match匹配是从前到后找，a是非数字，故而匹配失败</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#None</span></code></pre>
</li>
<li><p><code>findall</code> 方法：全部匹配，返回列表。以列表形式返回全部能匹配的子串，如果没有匹配，则返回一个空列表。</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 案例一：</span>
<span class="token keyword">import</span> re
strs <span class="token operator">=</span> r<span class="token string">'abc123def456'</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'\d+'</span><span class="token punctuation">)</span>
resu <span class="token operator">=</span> pattern<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>strs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#['123', '456']</span>
<span class="token comment" spellcheck="true">#--------------------------------------------------------</span>
<span class="token comment" spellcheck="true">## 案例二：</span>
<span class="token keyword">import</span> re
strs <span class="token operator">=</span> r<span class="token string">"123.14159 'bigcat'  232312  3.15"</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'\d+\.\d*'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#*是数量词</span>
resu <span class="token operator">=</span> pattern<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>strs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#['123.14159', '3.15']</span></code></pre>
</li>
<li><p><code>finditer</code> 方法：全部匹配，返回迭代器。跟 <code>findall</code> 的行为类似，也是搜索整个字符串，获得所有匹配的结果。但它返回一个顺序访问每一个匹配结果（<code>Match</code> 对象）的迭代器。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> re
strs <span class="token operator">=</span> r<span class="token string">"123.14159 'bigcat'  232312  3.15"</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'\d+\.\d*'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#*是数量词</span>
resu <span class="token operator">=</span> pattern<span class="token punctuation">.</span>finditer<span class="token punctuation">(</span>strs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>resu<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#&lt;class 'callable_iterator'></span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> resu<span class="token punctuation">:</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 123.14159</span>
<span class="token comment" spellcheck="true"># 3.15</span></code></pre>
</li>
<li><p><code>split</code> 方法：分割字符串，返回列表。按照能够匹配的子串将字符串分割后返回列表</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> re
strs <span class="token operator">=</span> r<span class="token string">"a,b;; c   d"</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'[\,\;\s]+'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#[]是字符集，也就是其中的任意一个</span>
resu <span class="token operator">=</span> pattern<span class="token punctuation">.</span>split<span class="token punctuation">(</span>strs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>resu<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &lt;class 'list'></span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu    <span class="token comment" spellcheck="true"># ['a', 'b', 'c', 'd']</span></code></pre>
</li>
<li><p><code>sub</code> 方法：替换，形式如下：<code>sub(repl, string[, count])</code><br><code>repl</code> 可以是字符串也可以是一个函数，表示用来替换的东西（或规则）：<br><code>repl</code> 是字符串，则会使用 <code>repl</code> 去替换字符串每一个匹配的子串，并返回替换后的字符串。<br><code>repl</code> 是函数，这个方法应当只接受一个参数（<code>Match</code> 对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。<br><code>count</code>用于指定最多替换次数，不指定时全部替换。</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 案例一：</span>
<span class="token keyword">import</span> re
partten <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'(\w+) (\w+)'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># \w = [A-Za-z0-9]  按空格分为两组，每一组内容是单词字符（匹配\w）</span>
s <span class="token operator">=</span> <span class="token string">'hello 123, hello 456'</span>
resu <span class="token operator">=</span> partten<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token string">'hello world'</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 使用 'hello world' 替换 'hello 123' 和 'hello 456'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># hello world, hello world</span>
resu <span class="token operator">=</span> partten<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token string">'\2 \1'</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 引用分组，默认前一个分组是\1,后一个是\2，故而这里是交换</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 123 hello, 456 hello</span>
<span class="token comment" spellcheck="true">#--------------------------------------------------------------------</span>
<span class="token comment" spellcheck="true">## 案例二：</span>
<span class="token keyword">import</span> re
partten <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'(\w+) (\w+)'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># \w = [A-Za-z0-9]  按空格分为两组，每一组内容是单词字符（匹配\w）</span>
s <span class="token operator">=</span> <span class="token string">'hello 123, hello 456'</span>
<span class="token keyword">def</span> <span class="token function">func</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">return</span> <span class="token string">'hi'</span> <span class="token operator">+</span> <span class="token string">' '</span> <span class="token operator">+</span> m<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#分组，即分组中的第二个</span>
resu <span class="token operator">=</span> partten<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>func<span class="token punctuation">,</span> s<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 不指定替换的次数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># hi 123, hi 456</span>
resu <span class="token operator">=</span> partten<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>func<span class="token punctuation">,</span> s<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true"># 最多替换一次</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># hi 123, hello 456</span></code></pre>
</li>
</ul>
<h3 id="匹配中文"><a href="#匹配中文" class="headerlink" title="匹配中文"></a>匹配中文</h3><p>中文的 unicode 编码范围 主要在 [u4e00-u9fa5]，这里说主要是因为这个范围并不完整，比如没有包括全角（中文）标点，不过，在大部分情况下，应该是够用的。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> re
title <span class="token operator">=</span> u<span class="token string">'你好，hello，世界'</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'[\u4e00-\u9fa5]+'</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> pattern<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>title<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#['你好', '世界']</span></code></pre>
<h3 id="爬虫中应用正则"><a href="#爬虫中应用正则" class="headerlink" title="爬虫中应用正则"></a>爬虫中应用正则</h3><p>如，我们这里想获取<a href="http://127.0.0.1：4000" target="_blank" rel="noopener">http://127.0.0.1：4000</a> 主页（地址也可以是本网站首页：<a href="http://baiyazi.top" target="_blank" rel="noopener">http://baiyazi.top</a> ）的文章的标题。浏览器检查一下，然后和标题相关的代码如下：</p>
<pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h2</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post-title<span class="token punctuation">"</span></span> <span class="token attr-name">itemprop</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>name headline<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post-title-link<span class="token punctuation">"</span></span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>/2019/usehexo-9/<span class="token punctuation">"</span></span> <span class="token attr-name">itemprop</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>url<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Hexo官网阅读笔记 | 来必力<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h2</span><span class="token punctuation">></span></span></code></pre>
<p>那么正则表达式就可以是：<code>r&#39;&lt;h2 .*&gt;\s+.*&lt;/h2&gt;&#39;</code><br>可以在一个程序中测试一下，如：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> re
title <span class="token operator">=</span> r<span class="token triple-quoted-string string">"""
&lt;h2 class="post-title" itemprop="name headline">

                &lt;a class="post-title-link" href="/2019/scrapy-8/" itemprop="url">seo-7 |  用Item数据封装&lt;/a>&lt;/h2>
"""</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'&lt;h2 .*>\s+.*&lt;/h2>'</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> pattern<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>title<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span> </code></pre>
<p>那么完整的程序如下：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> urllib
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> Request<span class="token punctuation">,</span>urlopen
<span class="token keyword">import</span> re

headers <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"</span>
<span class="token punctuation">}</span>

request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url<span class="token operator">=</span><span class="token string">"http://127.0.0.1:4000"</span><span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>
page <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#正则处理，找到发布的每一篇文章的标题</span>
pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'&lt;h2 .*>\s+.*&lt;/h2>'</span><span class="token punctuation">)</span>
resu <span class="token operator">=</span> pattern<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>page<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>resu<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 10</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> resu<span class="token punctuation">:</span>
    pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">"\s{2}"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 有空格，替换多个空格的</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>pattern<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>结果如下：</p>
<pre><code>10
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/introspection/&quot; itemprop=&quot;url&quot;&gt;My Reflective Notes&lt;/a&gt;&lt;/h2&gt;
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/usehexo-9/&quot; itemprop=&quot;url&quot;&gt;Hexo官网阅读笔记 | 来必力&lt;/a&gt;&lt;/h2&gt;
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/scrapy-8/&quot; itemprop=&quot;url&quot;&gt;seo-7 |用Item数据封装&lt;/a&gt;&lt;/h2&gt;
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/scrapy-7/&quot; itemprop=&quot;url&quot;&gt;scrapy-7 |Response内置CSS选择器&lt;/a&gt;&lt;/h2&gt;
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/scrapy-6/&quot; itemprop=&quot;url&quot;&gt;scrapy-6 |Response内置XPath选择器&lt;/a&gt;&lt;/h2&gt;
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/scrapy-5/&quot; itemprop=&quot;url&quot;&gt;scrapy-5 |Response内置Selector&lt;/a&gt;&lt;/h2&gt;
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/scrapy-4/&quot; itemprop=&quot;url&quot;&gt;scrapy-4 |Selector提取数据&lt;/a&gt;&lt;/h2&gt;
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/scrapy-3/&quot; itemprop=&quot;url&quot;&gt;scrapy-3 |Spider开发流程&lt;/a&gt;&lt;/h2&gt;
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/scrapy-2/&quot; itemprop=&quot;url&quot;&gt;scrapy-2 |第一个爬虫程序&lt;/a&gt;&lt;/h2&gt;
&lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt;&lt;a class=&quot;post-title-link&quot; href=&quot;/2019/scrapy-0/&quot; itemprop=&quot;url&quot;&gt;scrapy-0 |Python爬虫基础类库&lt;/a&gt;&lt;/h2&gt;</code></pre><h2 id="XPath选择器"><a href="#XPath选择器" class="headerlink" title="XPath选择器"></a>XPath选择器</h2><p>无疑，正则比较不怎么好用。需要比较熟悉正则表达式的规则，还是比较麻烦的。所以有比较简单的<code>XPath</code>来处理<code>xml</code>文档。由于<code>html</code>是特殊的<code>xml</code>文档，故而也可使用<code>XPath</code>。<br>可以安装：<code>Chrome</code>插件 <code>XPath Helper</code>，比较方便编程。</p>
<table border="1">
  <tr>
    <td>表达式</td>
    <td>说明</td>
  </tr>
  <tr>
    <td colspan="2" style="text-align:center;">选取节点</td>
  </tr>
  <tr>
    <td>nodename</td>
    <td>选取此节点的所有子节点。</td>
  </tr>
  <tr>
    <td>/</td>
    <td>从根节点选取。</td>
  </tr>
  <tr>
    <td>//</td>
    <td>从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。</td>
  </tr>
  <tr>
    <td>.</td>
    <td>选取当前节点。</td>
  </tr>
  <tr>
    <td>..</td>
    <td>选取当前节点的父节点。</td>
  </tr>
  <tr>
    <td>@</td>
    <td>选取属性。</td>
  </tr>
  <tr>
    <td colspan="2" style="text-align:center;">谓语用来查找某个特定的节点或者包含某个指定的值的节点，被嵌在方括号中。</td>
  </tr>
  <tr>
    <td>/bookstore/book[1]</td>
    <td>选取属于 bookstore 子元素的第一个 book 元素。</td>
  </tr>
  <tr>
    <td>/bookstore/book[last()]</td>
    <td>选取属于 bookstore 子元素的最后一个 book 元素。</td>
  </tr>
  <tr>
    <td>/bookstore/book[last()-1]</td>
    <td>选取属于 bookstore 子元素的倒数第二个 book 元素。</td>
  </tr>
  <tr>
    <td>/bookstore/book[position()< 3]</td>
    <td>选取最前面的两个属于 bookstore 元素的子元素的 book 元素。</td>
  </tr>
  <tr>
    <td>//title[@lang]</td>
    <td>选取所有拥有名为 lang 的属性的 title 元素。</td>
  </tr>
  <tr>
    <td>//title[@lang=’eng’]</td>
    <td>选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。</td>
  </tr>
  <tr>
    <td>/bookstore/book[price>35.00]</td>
    <td>选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。</td>
  </tr>
  <tr>
    <td>/bookstore/book<br>[price>35.00]/title</td>
    <td>选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00</td>
  </tr>

  <tr>
    <td colspan="2" style="text-align:center;">通配符</td>
  </tr>
  <tr>
    <td>*</td>
    <td>匹配任何元素节点。</td>
  </tr>
  <tr>
    <td>@</td>
    <td>匹配任何属性节点。</td>
  </tr>
  <tr>
    <td>node()</td>
    <td>匹配任何类型的节点。</td>
  </tr>
  <tr>
    <td>/bookstore/</td>
    <td>选取 bookstore 元素的所有子元素。</td>
  </tr>
  <tr>
    <td>//</td>
    <td>选取文档中的所有元素。</td>
  </tr>
  <tr>
    <td>//title[@*]</td>
    <td>选取所有带有属性的 title 元素。</td>
  </tr>
  <tr>
    <td colspan="2" style="text-align:center;">多选路径</td>
  </tr>
<tr><td>//book/title | //book/price</td><td>
选取 book 元素的所有 title 和 price 元素。</td></tr>
<tr><td>//title | //price</td><td>
选取文档中的所有 title 和 price 元素。</td></tr>
<tr><td>/bookstore/book/title | //price</td><td>
选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。</td></tr>
  </table>

<p>值得注意的是<code>XPath</code>全名是<code>XML Path Language</code>。也就是它是基于<code>xml</code>的一种路径选择语言，在<code>xml</code>文档中查找信息。<strong>在运用到<code>Python</code>抓取时要先转换为<code>xml</code>。</strong><br>故而我们需要先了解如何将一个文本页转换成xml节点树。</p>
<h3 id="lxml解析器"><a href="#lxml解析器" class="headerlink" title="lxml解析器"></a>lxml解析器</h3><p><code>lxml</code> 是 一个<code>HTML/XML</code>的解析器，主要的功能是如何解析和提取 <code>HTML/XML</code> 数据。<br><code>lxml python</code> 官方文档：<a href="http://lxml.de/index.html" target="_blank" rel="noopener">http://lxml.de/index.html</a><br>下面简单看一个案例：</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用 lxml 的 etree 库</span>
<span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree

content <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
&lt;ul>&lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>&lt;/ul>
"""</span>

<span class="token comment" spellcheck="true"># 利用etree.HTML，将字符串解析为HTML文档, 返回根结点</span>
html <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>html<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &lt;class 'lxml.etree._Element'></span>


<span class="token comment" spellcheck="true"># 序列化HTML文档，到一个特定编码的字符串</span>
result <span class="token operator">=</span> etree<span class="token punctuation">.</span>tostring<span class="token punctuation">(</span>html<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">,</span> pretty_print<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 默认的编码是 ASCII</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>结果：</p>
<pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span> <span class="token attr-name">'lxml.etree._Element'</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>html</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>body</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ul</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>item-0<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>link1.html<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>壹 item<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>item-1<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>link2.html<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>贰 item<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ul</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>body</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>html</span><span class="token punctuation">></span></span></code></pre>
<p>不难看出，大致补全了<code>HTML</code>文档结构。<br>下面，我们看看<code>xpath</code>是如何使用的，我们这里就来查找一下<code>a</code>标签：</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用 lxml 的 etree 库</span>
<span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree

content <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
&lt;ul>&lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>&lt;/ul>
"""</span>

<span class="token comment" spellcheck="true"># 利用etree.HTML，将字符串解析为HTML文档, 返回根结点</span>
html <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>html<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &lt;class 'lxml.etree._Element'></span>


ul_list <span class="token operator">=</span> html<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//li'</span><span class="token punctuation">)</span>
a_list <span class="token operator">=</span> html<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//a'</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> ul_list<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>etree<span class="token punctuation">.</span>tostring<span class="token punctuation">(</span>i<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># &lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li></span>
    <span class="token comment" spellcheck="true"># &lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li></span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> a_list<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 壹 item</span>
    <span class="token comment" spellcheck="true"># 贰 item</span>
</code></pre>
<p>当然，不止是常量字符串，还可以读取<code>HTML</code>文档。所用的方法是：<code>etree.parse()</code>，不妨看看原型：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>source<span class="token punctuation">,</span> parser<span class="token operator">=</span>None<span class="token punctuation">,</span> base_url<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># real signature unknown; restored from __doc__</span>
    <span class="token triple-quoted-string string">"""
    parse(source, parser=None, base_url=None)

        Return an ElementTree object loaded with source elements.  If no parser
        is provided as second argument, the default parser is used.

        The ``source`` can be any of the following:

        - a file name/path
        - a file object
        - a file-like object
        - a URL using the HTTP or FTP protocol

        To parse from a string, use the ``fromstring()`` function instead.

        Note that it is generally faster to parse from a file path or URL
        than from an open file object or file-like object.  Transparent
        decompression from gzip compressed sources is supported (unless
        explicitly disabled in libxml2).

        The ``base_url`` keyword allows setting a URL for the document
        when parsing from a file-like object.  This is needed when looking
        up external entities (DTD, XInclude, ...) with relative paths.
    """</span>
    <span class="token keyword">pass</span></code></pre>
<p>可以放置的资源文件可以是一个文件路径、文件对象、文件链接地址。比较方便。<br>案例：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree

<span class="token comment" spellcheck="true"># 读取外部文件 hello.html</span>
html <span class="token operator">=</span> etree<span class="token punctuation">.</span>parse<span class="token punctuation">(</span><span class="token string">'./hello.html'</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> etree<span class="token punctuation">.</span>tostring<span class="token punctuation">(</span>html<span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">"utf-8"</span>， pretty_print<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h3 id="爬虫-使用XPath解析案例"><a href="#爬虫-使用XPath解析案例" class="headerlink" title="爬虫+使用XPath解析案例"></a>爬虫+使用XPath解析案例</h3><p>下面一起看看案例，我们下载<a href="http://127.0.0.1:4000" target="_blank" rel="noopener">http://127.0.0.1:4000</a> 即网站主页的图片，检查代码如下：</p>
<pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>site-author-image<span class="token punctuation">"</span></span> <span class="token attr-name">itemprop</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>image<span class="token punctuation">"</span></span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>/images/avatar.jpg<span class="token punctuation">"</span></span> <span class="token attr-name">alt</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>无涯明月<span class="token punctuation">"</span></span><span class="token punctuation">></span></span></code></pre>
<p>很容易得出<code>img</code>标签的<code>src</code>地址<code>XPath</code>，可以是<code>//img/@src</code></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> urllib
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> Request<span class="token punctuation">,</span>urlopen
<span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree
<span class="token keyword">import</span> re

headers <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"</span>
<span class="token punctuation">}</span>

request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url<span class="token operator">=</span><span class="token string">"http://127.0.0.1:4000"</span><span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>
page <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 解析html 为 HTML 文档</span>
selector <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>page<span class="token punctuation">)</span>
links <span class="token operator">=</span> selector<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//img/@src'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 使用xpath选择器，取出所有img标签，的src。得到列表集</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>links<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;class 'list'></span>

resu <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 正则匹配一下，我不想要fork me on github的图片，只想要本网站的图片</span>
<span class="token keyword">for</span> link <span class="token keyword">in</span> links<span class="token punctuation">:</span>
    pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'/images/.*.[(jpg)(png)]'</span><span class="token punctuation">)</span>
    resu <span class="token operator">+=</span> pattern<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>link<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># ['/images/avatar.jpg'， '/images/beian/beian.png']</span>

<span class="token comment" spellcheck="true"># 下载图片</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> resu<span class="token punctuation">:</span>
    request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url <span class="token operator">=</span> <span class="token string">"http://127.0.0.1:4000"</span> <span class="token operator">+</span> i<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
    response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>
    file <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
    pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>r<span class="token string">'[A-Za-z0-9_]+\.[a-z]{3}'</span><span class="token punctuation">)</span>
    filename <span class="token operator">=</span> pattern<span class="token punctuation">.</span>search<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'开始下载'</span><span class="token punctuation">.</span>center<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token string">'-'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> filename<span class="token punctuation">)</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"d:/"</span> <span class="token operator">+</span> filename<span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>file<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'完成下载'</span><span class="token punctuation">.</span>center<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token string">'-'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> filename<span class="token punctuation">)</span>
</code></pre>
<p>然后，在<code>D</code>盘中就可以看见下载的两种图片。</p>
<h2 id="CSS选择器"><a href="#CSS选择器" class="headerlink" title="CSS选择器"></a>CSS选择器</h2><p>和<code>lxml</code> 一样，<code>Beautiful Soup</code> 也是一个<code>HTML/XML</code>的解析器，主要的功能也是如何解析和提取 <code>HTML/XML</code> 数据。<br>官方文档：<a href="http://beautifulsoup.readthedocs.io/zh_CN/v4.4.0" target="_blank" rel="noopener">http://beautifulsoup.readthedocs.io/zh_CN/v4.4.0</a><br><code>pip</code> 安装：<code>pip install beautifulsoup4</code><br><code>lxml</code> 只会局部遍历，而<code>Beautiful Soup</code> 是基于<code>HTML DOM</code>的，会载入整个文档，解析整个<code>DOM</code>树，因此时间和内存开销都会大很多，所以性能要低于<code>lxml</code>。</p>
<table><thead><tr><th style="text-align:center">抓取工具</th><th style="text-align:center">速度</th><th style="text-align:center">使用难度</th><th style="text-align:center">安装难度</th></tr></thead><tbody><tr><td style="text-align:center">正则</td><td style="text-align:center">最快</td><td style="text-align:center">困难</td><td style="text-align:center">无（内置）</td></tr><tr><td style="text-align:center">BeautifulSoup</td><td style="text-align:center">慢</td><td style="text-align:center">最简单</td><td style="text-align:center">简单</td></tr><tr><td style="text-align:center">lxml</td><td style="text-align:center">快</td><td style="text-align:center">简单</td><td style="text-align:center">一般</td></tr></tbody></table>
### 常见的文档树处理函数
Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象。
* 常见的标签处理：Tag
Tag 通俗点讲就是 HTML 中的一个个标签。但是注意，**它查找的是在所有内容中的第一个符合要求的标签。** 
还有值得注意的是：**对于 Tag，它有两个重要的属性，是 name 和 attrs**
看看下面的例子：

<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup
content <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
&lt;ul>&lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>&lt;/ul>
"""</span>

soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>content<span class="token punctuation">,</span> features<span class="token operator">=</span><span class="token string">"html.parser"</span><span class="token punctuation">)</span>
li <span class="token operator">=</span> soup<span class="token punctuation">.</span>li
<span class="token keyword">print</span><span class="token punctuation">(</span>li<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li></span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>li<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &lt;class 'bs4.element.Tag'></span>

<span class="token comment" spellcheck="true"># 两个属性</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>li<span class="token punctuation">.</span>name<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># li</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>li<span class="token punctuation">.</span>attrs<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># {'class': ['item-0']}</span></code></pre>
<ul>
<li>获取标签文本域内容<br>获取标签内部的文字对象。有三种方式，看看下面简单的例子：</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

content <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
&lt;ul>&lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>&lt;/ul>
"""</span>

soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>content<span class="token punctuation">,</span> features<span class="token operator">=</span><span class="token string">"html.parser"</span><span class="token punctuation">)</span>
li <span class="token operator">=</span> soup<span class="token punctuation">.</span>li
<span class="token keyword">print</span><span class="token punctuation">(</span>li<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li></span>
<span class="token comment" spellcheck="true"># print(li.next_siblings)  # li</span>

<span class="token comment" spellcheck="true"># 获取文本节点</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>li<span class="token punctuation">.</span>string<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 壹 item</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>li<span class="token punctuation">.</span>text<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 壹 item</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>li<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 壹 item</span></code></pre>
<ul>
<li>find-搜索文档树</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

content <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
&lt;ul>&lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>&lt;/ul>
"""</span>

soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>content<span class="token punctuation">,</span> features<span class="token operator">=</span><span class="token string">"html.parser"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>soup<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;class 'bs4.BeautifulSoup'></span>

<span class="token comment" spellcheck="true"># find  匹配第一个满足的</span>
li <span class="token operator">=</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'li'</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li></span>

<span class="token comment" spellcheck="true"># find_all   匹配所有，返回列表集</span>
li_list <span class="token operator">=</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'li'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [&lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>, &lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>]</span>

<span class="token comment" spellcheck="true"># find_next 在当前标签向后查找给定的标签，匹配第一个</span>
li <span class="token operator">=</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'li'</span><span class="token punctuation">)</span>
next_li <span class="token operator">=</span> li<span class="token punctuation">.</span>find_next<span class="token punctuation">(</span><span class="token string">'li'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li></span>
next_a <span class="token operator">=</span> li<span class="token punctuation">.</span>find_next<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;a href="link1.html">壹 item&lt;/a></span>

<span class="token comment" spellcheck="true"># find_all_next  在当前标签向后查找给定的标签，匹配所有</span>
ul <span class="token operator">=</span> soup<span class="token punctuation">.</span>ul
a_list <span class="token operator">=</span> ul<span class="token punctuation">.</span>find_all_next<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [&lt;a href="link1.html">壹 item&lt;/a>, &lt;a href="link2.html">贰 item&lt;/a>]</span>

<span class="token comment" spellcheck="true"># find_previous 在当前标签向前查找给定的标签，匹配首个</span>
last_a <span class="token operator">=</span> a_list<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>   <span class="token comment" spellcheck="true"># &lt;a href="link2.html">贰 item&lt;/a></span>
li <span class="token operator">=</span> last_a<span class="token punctuation">.</span>find_previous<span class="token punctuation">(</span><span class="token string">'li'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li></span>
a <span class="token operator">=</span> last_a<span class="token punctuation">.</span>find_previous<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &lt;a href="link1.html">壹 item&lt;/a></span>

<span class="token comment" spellcheck="true"># find_all_previous  在当前标签向前查找给定的标签，匹配所有</span>
li_list <span class="token operator">=</span> last_a<span class="token punctuation">.</span>find_all_previous<span class="token punctuation">(</span><span class="token string">'li'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>, &lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>]</span>
a_list <span class="token operator">=</span> last_a<span class="token punctuation">.</span>find_all_previous<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [&lt;a href="link1.html">壹 item&lt;/a>]</span>

<span class="token comment" spellcheck="true"># find_parent  name默认None,返回直接父辈元素。写name可以是上上级，就返回上上级父元素标签</span>
li <span class="token operator">=</span> last_a<span class="token punctuation">.</span>find_parent<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 直接父元素 &lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li></span>
ul <span class="token operator">=</span> last_a<span class="token punctuation">.</span>find_parent<span class="token punctuation">(</span><span class="token string">'ul'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 指定父元素 &lt;ul>&lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>&lt;/ul></span>

<span class="token comment" spellcheck="true"># find_parents</span>
parents <span class="token operator">=</span> last_a<span class="token punctuation">.</span>find_parents<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 直接父元素 和上层所有父辈元素</span>
<span class="token comment" spellcheck="true"># [&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>, &lt;ul>&lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>&lt;/ul>,</span>
<span class="token comment" spellcheck="true"># &lt;ul>&lt;li class="item-0">&lt;a href="link1.html">壹 item&lt;/a>&lt;/li>&lt;li class="item-1">&lt;a href="link2.html">贰 item&lt;/a>&lt;/li>&lt;/ul>,</span>
<span class="token comment" spellcheck="true"># ]</span>

<span class="token comment" spellcheck="true"># 下面四个方法是兄弟元素的相关方法，不演示了。</span>
<span class="token comment" spellcheck="true">#  'find_next_sibling', 'find_next_siblings'</span>
<span class="token comment" spellcheck="true">#  'find_previous_sibling', 'find_previous_siblings',</span></code></pre>
<h3 id="select方法-按照CSS选择器查找"><a href="#select方法-按照CSS选择器查找" class="headerlink" title="select方法-按照CSS选择器查找"></a>select方法-按照CSS选择器查找</h3><p>不妨看一个简单的案例：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

body <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
&lt;ul>
&lt;li class='s'>1 2 3&lt;/li>
&lt;li id='t'>one two three&lt;/li>
&lt;li>壹 贰 叁&lt;/li>
&lt;li>一 二 三&lt;/li>
&lt;/ul>
"""</span>

soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>body<span class="token punctuation">,</span> features<span class="token operator">=</span><span class="token string">'html.parser'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 标签选择器，直接使用名字</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'ul'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># [&lt;ul>...&lt;/ul>]</span>
<span class="token comment" spellcheck="true"># 类选择器</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'ul li.s'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># [&lt;li class="s">1 2 3&lt;/li>]</span>
<span class="token comment" spellcheck="true"># id选择器</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'li#t'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   # <span class="token punctuation">[</span><span class="token operator">&lt;</span>li id<span class="token operator">=</span><span class="token string">"t"</span><span class="token operator">></span>one two three<span class="token operator">&lt;</span><span class="token operator">/</span>li<span class="token operator">></span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 子元素选择器 ></span>
<span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'ul > li'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [&lt;li class="s">1 2 3&lt;/li>, &lt;li id="t">one two three&lt;/li>, &lt;li>壹 贰 叁&lt;/li>, &lt;li>一 二 三&lt;/li>]</span></code></pre>
<p>不妨看看本网站关于<a href="/2019/css-2/">CSS选择器的教程</a></p>
<h3 id="按照属性查找"><a href="#按照属性查找" class="headerlink" title="按照属性查找"></a>按照属性查找</h3><p>当然，标签中可能有其他的属性，我们可以按照属性查找：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

body <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
&lt;input type="text" name="user"/>
&lt;input type="email" name="em"/>
&lt;input type="password" name="ps"/>
"""</span>

<span class="token comment" spellcheck="true"># 使用字符串常量，创建 Beautiful Soup 对象</span>
soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>body<span class="token punctuation">,</span> features<span class="token operator">=</span><span class="token string">'html.parser'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 使用本地HTML文件，创建对象 Beautiful Soup 对象</span>
<span class="token comment" spellcheck="true"># soup = BeautifulSoup(open('index.html'))</span>

<span class="token comment" spellcheck="true"># 格式化输出 soup 对象的内容</span>
<span class="token comment" spellcheck="true"># print soup.prettify()</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'input[type="password"]'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#  [&lt;input name="ps" type="password"/>]</span>


<span class="token comment" spellcheck="true"># soup.select('p a[href="http://example.com/elsie"]')</span></code></pre>
<h3 id="获取标签文本内容"><a href="#获取标签文本内容" class="headerlink" title="获取标签文本内容"></a>获取标签文本内容</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

body <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
&lt;span class="w">&lt;b>挡泥&lt;/b>&lt;/span>
&lt;span id="r">老路&lt;/span> 
"""</span>

soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>body<span class="token punctuation">,</span> features<span class="token operator">=</span><span class="token string">'html.parser'</span><span class="token punctuation">)</span>
resu <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'span'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>resu<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;class 'bs4.element.Tag'></span>
<span class="token comment" spellcheck="true"># bs4.element.Tag.get_text()  # Get all child strings, concatenated using the given separator.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 挡泥</span>

<span class="token comment" spellcheck="true"># 获取文本节点三种方式都可以：</span>
<span class="token comment" spellcheck="true"># resu[0].string  </span>
<span class="token comment" spellcheck="true"># resu[0].text   </span>
<span class="token comment" spellcheck="true"># resu[0].get_text()  </span></code></pre>
<h2 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h2><p>和<code>xml</code>的地位不相上下，很厉害。<code>Json</code>在线解析网站：<a href="http://www.json.cn/#" target="_blank" rel="noopener">http://www.json.cn/#</a><br><code>json</code>简单说就是<code>javascript</code>中的对象和数组，所以这两种结构就是对象和数组两种结构，通过这两种结构可以表示各种复杂的结构<br><code>json</code>模块提供了四个功能：<code>dumps</code>、<code>dump</code>、<code>loads</code>、<code>load</code>，用于字符串 和 <code>python</code>数据类型间进行转换。</p>
<ol>
<li><code>loads</code><br><code>Json</code>格式字符串解码转换成<code>Python</code>对象</li>
</ol>
<ul>
<li>JSON object ==&gt; Python dict</li>
<li>JSON array  ==&gt; Python list</li>
<li>JSON string ==&gt; Python unicode</li>
<li>JSON number(int)  ==&gt; Python int,long</li>
<li>JSON number(real) ==&gt; Python float</li>
<li>JSON true ==&gt; Python True</li>
<li>JSON false  ==&gt; Python False</li>
<li>JSON null  ==&gt; Python None</li>
</ul>
<h2 id="案例："><a href="#案例：" class="headerlink" title="案例："></a>案例：</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span>  json
jstr <span class="token operator">=</span> <span class="token string">'{"city": "北京", "name": "大猫"}'</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>jstr<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;class 'dict'></span>
<span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>jstr<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># {'city': '北京', 'name': '大猫'}</span></code></pre>
<ol start="2">
<li><code>dumps</code><br>把一个<code>Python</code>对象编码转换成Json字符串，返回一个<code>str</code>对象。<br>转换的规则，刚好和上面的相反。</li>
</ol>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span>  json

jstr <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"city"</span><span class="token punctuation">:</span> <span class="token string">"北京"</span><span class="token punctuation">,</span> <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"大猫"</span><span class="token punctuation">}</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>jstr<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;class 'str'></span>
<span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>jstr<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># {"city": "\u5317\u4eac", "name": "\u5927\u732b"}</span>

<span class="token comment" spellcheck="true"># json.dumps() 序列化时默认使用的ascii编码</span>
<span class="token comment" spellcheck="true"># 添加参数 ensure_ascii=False 禁用ascii编码，按utf-8编码</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>jstr<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;class 'str'></span>
<span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>jstr<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># {"city": "北京", "name": "大猫"}</span></code></pre>
<p>另外的<code>dump</code>、<code>load</code>就不介绍了，是操作文件的。下面就介绍解析<code>JSON</code>文件的<code>JsonPath</code></p>
<h3 id="JsonPath"><a href="#JsonPath" class="headerlink" title="JsonPath"></a>JsonPath</h3><p><code>JsonPath</code> 是一种信息抽取类库，是从<code>JSON</code>文档中抽取指定信息的工具，提供多种语言实现版本，包括：<code>Javascript</code>, <code>Python</code>， <code>PHP</code> 和 <code>Java</code>。<br>下载地址：<a href="https://pypi.python.org/pypi/jsonpath" target="_blank" rel="noopener">https://pypi.python.org/pypi/jsonpath</a><br>安装方法：点击<code>Download URL</code>链接下载<code>jsonpath</code>，解压之后执行<code>python setup.py install</code><br>官方文档：<a href="http://goessner.net/articles/JsonPath" target="_blank" rel="noopener">http://goessner.net/articles/JsonPath</a><br>由于我使用的是<code>Pycharm</code>工具，比较方便，直接设置中安装就可以了。<br><code>JsonPath</code>与<code>XPath</code>语法对比：</p>
<table><thead><tr><th style="text-align:center">XPath</th><th>JSONPath</th><th>描述</th></tr></thead><tbody><tr><td style="text-align:center"><code>/</code></td><td><code>$</code></td><td>根节点</td></tr><tr><td style="text-align:center"><code>.</code></td><td><code>@</code></td><td>现行节点</td></tr><tr><td style="text-align:center"><code>/</code></td><td><code>.</code>or<code>[]</code></td><td>取子节点</td></tr><tr><td style="text-align:center"><code>..</code></td><td>n/a</td><td>取父节点，Jsonpath未支持</td></tr><tr><td style="text-align:center"><code>//</code></td><td><code>..</code></td><td>就是不管位置，选择所有符合条件的条件</td></tr><tr><td style="text-align:center"><code>\*</code></td><td><code>\*</code></td><td>匹配所有元素节点</td></tr><tr><td style="text-align:center"><code>@</code></td><td>n/a</td><td>根据属性访问，Json不支持，因为Json是个Key-value递归结构，不需要。</td></tr><tr><td style="text-align:center"><code>[]</code></td><td><code>[]</code></td><td>迭代器标示（可以在里边做简单的迭代操作，如数组下标，根据内容选值等）</td></tr><tr><td style="text-align:center">|</td><td><code>[,]</code></td><td>支持迭代器中做多选。</td></tr><tr><td style="text-align:center"><code>[]</code></td><td><code>?()</code></td><td>支持过滤操作.</td></tr><tr><td style="text-align:center">n/a</td><td><code>()</code></td><td>支持表达式计算</td></tr><tr><td style="text-align:center"><code>()</code></td><td>n/a</td><td>分组，JsonPath不支持</td></tr></tbody></table>

<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>以<a href="http://www.lagou.com/lbs/getAllCitySearchLabels.json" target="_blank" rel="noopener">http://www.lagou.com/lbs/getAllCitySearchLabels.json</a> 为例。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> urllib
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> Request<span class="token punctuation">,</span>urlopen
<span class="token keyword">import</span> jsonpath
<span class="token keyword">import</span> json

headers <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"</span>
<span class="token punctuation">}</span>

request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url<span class="token operator">=</span><span class="token string">"http://www.lagou.com/lbs/getAllCitySearchLabels.json"</span><span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>
page <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># print(page)</span>
<span class="token comment" spellcheck="true"># 把json格式字符串转换成python对象</span>
jsonobj <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>page<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 从根节点开始，匹配name节点</span>
resu <span class="token operator">=</span> jsonpath<span class="token punctuation">.</span>jsonpath<span class="token punctuation">(</span>jsonobj<span class="token punctuation">,</span> <span class="token string">'$..name'</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>resu<span class="token punctuation">)</span>
</code></pre>
<h2 id="案例：爬取主页中的内容"><a href="#案例：爬取主页中的内容" class="headerlink" title="案例：爬取主页中的内容"></a>案例：爬取主页中的内容</h2><p>要求：</p>
<ul>
<li>使用requests获取页面信息，用XPath / re 做数据提取</li>
<li>获取每个帖子里的标题、标题链接、发文日期、字数统计、缩略内容</li>
<li>保存到 json 文件内</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> urllib
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> Request<span class="token punctuation">,</span>urlopen
<span class="token keyword">import</span> json
<span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree

headers <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36"</span>
<span class="token punctuation">}</span>
request <span class="token operator">=</span> Request<span class="token punctuation">(</span>url<span class="token operator">=</span><span class="token string">"http://127.0.0.1:4000"</span><span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
response <span class="token operator">=</span> urlopen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>
page <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

html <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>text<span class="token operator">=</span>page<span class="token punctuation">)</span>
articles <span class="token operator">=</span> html<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id="posts"]/article'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># for i in articles:</span>
<span class="token comment" spellcheck="true">#     print(etree.tostring(i, encoding='utf-8').decode('utf-8'))</span>

<span class="token keyword">for</span> article <span class="token keyword">in</span> articles<span class="token punctuation">:</span>
    title <span class="token operator">=</span> article<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//div/header/h2/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    link <span class="token operator">=</span> <span class="token string">"http://127.0.0.1:4000"</span> <span class="token operator">+</span> article<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//div/header/h2/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 标题、标题链接、发文日期、字数统计、缩略内容</span>
    time <span class="token operator">=</span> article<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//div/header/div/span[1]/time/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
    count <span class="token operator">=</span> article<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//div/header/div/div/span[3]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> article<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//div/div[1]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">14</span><span class="token punctuation">]</span>
    file_content <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">"title"</span><span class="token punctuation">:</span>title<span class="token punctuation">,</span>
        <span class="token string">"link"</span><span class="token punctuation">:</span>link<span class="token punctuation">,</span>
        <span class="token string">"time"</span><span class="token punctuation">:</span>time<span class="token punctuation">,</span>
        <span class="token string">"count"</span><span class="token punctuation">:</span>count<span class="token punctuation">,</span>
        <span class="token string">"content"</span><span class="token punctuation">:</span>content
    <span class="token punctuation">}</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 转换字典成为json字符串</span>
    <span class="token comment" spellcheck="true"># print(json.dumps(file_content,ensure_ascii=False).encode('utf-8').decode('utf-8'))</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"d:/a.json"</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>file_content<span class="token punctuation">,</span>ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span></code></pre>
<p>结果截图：<br><img src="/images/201906/2019-06-25_105226.jpg" alt="e"></p>

            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>Reprint policy</span>
        </p>
        
            <div class="center-align">
                <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《scrapy-0 |  Python爬虫基础 一》
                </span> by
            <a xmlns:cc="http://creativecommons.org/ns#" href="/2019/06/scrapy-0/" property="cc:attributionName"
               rel="cc:attributionURL">
                梦否
            </a> is licensed under a
            <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">
                Creative Commons Attribution 4.0 International License
            </a> 
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2019/06/scrapy-2/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/8.jpg" class="responsive-img" alt="scrapy-2 |  第一个爬虫程序">
                        
                        <span class="card-title">scrapy-2 |  第一个爬虫程序</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            安装完成了，接下来，我们开始写程序。
#1 查看帮助
    scrapy -h
    scrapy  -h
#2 有两种命令：其中Project-only必须切到项目文件夹下才能执行，而Global的命令则不需要
    Global 
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2019-06-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/scrapy/" class="post-category" target="_blank">
                                    scrapy
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/scrapy/" target="_blank">
                        <span class="chip bg-color">scrapy</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2019/06/scrapy-1/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/12.jpg" class="responsive-img" alt="scrapy-1 |  安装scrapy">
                        
                        <span class="card-title">scrapy-1 |  安装scrapy</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            决定系统化的学习爬虫，使用Python实现。以下内容来自博客园、CSDN等。非原创。
1、安装wheel（安装后，便支持通过wheel文件安装软件）pip3 install wheel
2、安装lxml、pyopenssllxml：解析XM
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-06-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/scrapy/" class="post-category" target="_blank">
                                    scrapy
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/scrapy/" target="_blank">
                        <span class="chip bg-color">scrapy</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + 'From: 梦否<br />'
            + 'Author: 梦否<br />'
            + 'Link: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            &copy;2019&nbsp;&nbsp;Baiyazi &nbsp;Base on &nbsp;<font style="color:#eee;">matery</font>&nbsp;主题.

            
                &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
                <span class="white-color">181.3k</span>
            

            
			
                <br>
                
                <span id="busuanzi_container_site_pv">
                    <i class="fa fa-heart-o"></i>
                    本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
                </span>
                
                
                <span id="busuanzi_container_site_uv">
                    <i class="fa fa-users"></i>
                    次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
                </span>
                <div style="width:300px;margin:0 auto; padding:20px 0;">
		    <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=51010802000714" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;"><img src="/images/beian/beian.png" style="float:left;"/><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#DBDBDB;">川公网安备 51010802000714号</p></a>
		</div>
		
            	 
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/baiyazi" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:1270563429@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1270563429" class="tooltipped" data-tooltip="QQ联系我: 1270563429" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>


<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>